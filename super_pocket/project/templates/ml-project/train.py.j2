"""Training script for {{ project_name }}."""
{% if tool_choices.framework == "pytorch" %}
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
{% elif tool_choices.framework == "tensorflow" %}
import tensorflow as tf
from tensorflow import keras
{% elif tool_choices.framework == "sklearn" %}
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
{% endif %}
import numpy as np
from sklearn.model_selection import train_test_split
{% if tool_choices.experiment_tracking == "mlflow" %}
import mlflow
import mlflow.{{ tool_choices.framework if tool_choices.framework != "sklearn" else "sklearn" }}
{% elif tool_choices.experiment_tracking == "wandb" %}
import wandb
{% endif %}
from .config import config


{% if tool_choices.framework == "pytorch" %}
class SimpleModel(nn.Module):
    """Simple neural network model."""

    def __init__(self, input_size: int, hidden_size: int, output_size: int):
        super().__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x


def train_model(X_train, y_train, X_test, y_test):
    """Train PyTorch model."""
    # Set random seed
    torch.manual_seed(config.random_seed)

    # Create datasets and dataloaders
    train_dataset = TensorDataset(
        torch.FloatTensor(X_train), torch.LongTensor(y_train)
    )
    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)

    # Initialize model
    input_size = X_train.shape[1]
    output_size = len(np.unique(y_train))
    model = SimpleModel(input_size=input_size, hidden_size=64, output_size=output_size)

    # Move to device
    device = torch.device(config.device if torch.cuda.is_available() else "cpu")
    model = model.to(device)

    # Loss and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)

{% if tool_choices.experiment_tracking == "mlflow" %}
    # Start MLflow run
    mlflow.set_tracking_uri(config.mlflow_tracking_uri)
    mlflow.set_experiment(config.experiment_name)

    with mlflow.start_run():
        # Log parameters
        mlflow.log_params({
            "learning_rate": config.learning_rate,
            "batch_size": config.batch_size,
            "num_epochs": config.num_epochs,
            "optimizer": "Adam",
        })
{% elif tool_choices.experiment_tracking == "wandb" %}
    # Initialize W&B
    wandb.init(
        project=config.wandb_project,
        entity=config.wandb_entity,
        config={
            "learning_rate": config.learning_rate,
            "batch_size": config.batch_size,
            "num_epochs": config.num_epochs,
            "optimizer": "Adam",
        },
    )
    wandb.watch(model)
{% endif %}

        # Training loop
        for epoch in range(config.num_epochs):
            model.train()
            total_loss = 0

            for batch_X, batch_y in train_loader:
                batch_X, batch_y = batch_X.to(device), batch_y.to(device)

                # Forward pass
                outputs = model(batch_X)
                loss = criterion(outputs, batch_y)

                # Backward pass
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                total_loss += loss.item()

            avg_loss = total_loss / len(train_loader)
            print(f"Epoch [{epoch+1}/{config.num_epochs}], Loss: {avg_loss:.4f}")

{% if tool_choices.experiment_tracking == "mlflow" %}
            mlflow.log_metric("loss", avg_loss, step=epoch)
{% elif tool_choices.experiment_tracking == "wandb" %}
            wandb.log({"loss": avg_loss, "epoch": epoch})
{% endif %}

        # Evaluate
        model.eval()
        with torch.no_grad():
            X_test_tensor = torch.FloatTensor(X_test).to(device)
            predictions = model(X_test_tensor)
            _, predicted = torch.max(predictions, 1)
            accuracy = (predicted.cpu().numpy() == y_test).mean()

        print(f"Test Accuracy: {accuracy:.4f}")

{% if tool_choices.experiment_tracking == "mlflow" %}
        mlflow.log_metric("accuracy", accuracy)
        mlflow.pytorch.log_model(model, "model")
{% elif tool_choices.experiment_tracking == "wandb" %}
        wandb.log({"test_accuracy": accuracy})
        wandb.finish()
{% endif %}

        # Save model
        model_path = config.models_dir / "model.pt"
        torch.save(model.state_dict(), model_path)
        print(f"Model saved to {model_path}")

{% elif tool_choices.framework == "tensorflow" %}
def create_model(input_shape, num_classes):
    """Create TensorFlow model."""
    model = keras.Sequential([
        keras.layers.Dense(64, activation='relu', input_shape=input_shape),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(32, activation='relu'),
        keras.layers.Dense(num_classes, activation='softmax')
    ])
    return model


def train_model(X_train, y_train, X_test, y_test):
    """Train TensorFlow model."""
    # Set random seed
    tf.random.set_seed(config.random_seed)

    # Prepare data
    num_classes = len(np.unique(y_train))
    y_train_cat = keras.utils.to_categorical(y_train, num_classes)
    y_test_cat = keras.utils.to_categorical(y_test, num_classes)

    # Create model
    model = create_model(input_shape=(X_train.shape[1],), num_classes=num_classes)
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=config.learning_rate),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

{% if tool_choices.experiment_tracking == "mlflow" %}
    # Start MLflow run
    mlflow.set_tracking_uri(config.mlflow_tracking_uri)
    mlflow.set_experiment(config.experiment_name)

    with mlflow.start_run():
        # Log parameters
        mlflow.log_params({
            "learning_rate": config.learning_rate,
            "batch_size": config.batch_size,
            "epochs": config.epochs,
            "optimizer": "Adam",
        })
{% elif tool_choices.experiment_tracking == "wandb" %}
    # Initialize W&B
    wandb.init(
        project=config.wandb_project,
        entity=config.wandb_entity,
        config={
            "learning_rate": config.learning_rate,
            "batch_size": config.batch_size,
            "epochs": config.epochs,
            "optimizer": "Adam",
        },
    )
{% endif %}

        # Train model
        history = model.fit(
            X_train, y_train_cat,
            batch_size=config.batch_size,
            epochs=config.epochs,
            validation_data=(X_test, y_test_cat),
            verbose=1
        )

        # Evaluate
        test_loss, test_accuracy = model.evaluate(X_test, y_test_cat, verbose=0)
        print(f"Test Accuracy: {test_accuracy:.4f}")

{% if tool_choices.experiment_tracking == "mlflow" %}
        mlflow.log_metric("accuracy", test_accuracy)
        mlflow.tensorflow.log_model(model, "model")
{% elif tool_choices.experiment_tracking == "wandb" %}
        wandb.log({"test_accuracy": test_accuracy})
        wandb.finish()
{% endif %}

        # Save model
        model_path = config.models_dir / "model.h5"
        model.save(model_path)
        print(f"Model saved to {model_path}")

{% elif tool_choices.framework == "sklearn" %}
def train_model(X_train, y_train, X_test, y_test):
    """Train scikit-learn model."""
    # Set random seed
    np.random.seed(config.random_seed)

    # Initialize model
    model = RandomForestClassifier(
        n_estimators=config.n_estimators,
        max_depth=config.max_depth,
        random_state=config.random_seed
    )

{% if tool_choices.experiment_tracking == "mlflow" %}
    # Start MLflow run
    mlflow.set_tracking_uri(config.mlflow_tracking_uri)
    mlflow.set_experiment(config.experiment_name)

    with mlflow.start_run():
        # Log parameters
        mlflow.log_params({
            "n_estimators": config.n_estimators,
            "max_depth": config.max_depth,
            "random_state": config.random_seed,
        })
{% elif tool_choices.experiment_tracking == "wandb" %}
    # Initialize W&B
    wandb.init(
        project=config.wandb_project,
        entity=config.wandb_entity,
        config={
            "n_estimators": config.n_estimators,
            "max_depth": config.max_depth,
            "random_state": config.random_seed,
        },
    )
{% endif %}

        # Train model
        print("Training model...")
        model.fit(X_train, y_train)

        # Evaluate
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print(f"\nTest Accuracy: {accuracy:.4f}")
        print("\nClassification Report:")
        print(classification_report(y_test, y_pred))

{% if tool_choices.experiment_tracking == "mlflow" %}
        mlflow.log_metric("accuracy", accuracy)
        mlflow.sklearn.log_model(model, "model")
{% elif tool_choices.experiment_tracking == "wandb" %}
        wandb.log({"test_accuracy": accuracy})
        wandb.finish()
{% endif %}

        # Save model
        import joblib
        model_path = config.models_dir / "model.pkl"
        joblib.dump(model, model_path)
        print(f"\nModel saved to {model_path}")

{% else %}
def train_model(X_train, y_train, X_test, y_test):
    """Train custom model."""
    # Set random seed
    np.random.seed(config.random_seed)

{% if tool_choices.experiment_tracking == "mlflow" %}
    # Start MLflow run
    mlflow.set_tracking_uri(config.mlflow_tracking_uri)
    mlflow.set_experiment(config.experiment_name)

    with mlflow.start_run():
        # Log parameters
        mlflow.log_params({
            "test_size": config.test_size,
            "random_seed": config.random_seed,
        })

        # Implement your training logic here
        print("Training custom model...")
        print(f"Training data shape: {X_train.shape}")
        print(f"Test data shape: {X_test.shape}")

        # TODO: Add your model training code here

        # Log metrics
        # mlflow.log_metric("metric_name", metric_value)
{% elif tool_choices.experiment_tracking == "wandb" %}
    # Initialize W&B
    wandb.init(
        project=config.wandb_project,
        entity=config.wandb_entity,
        config={
            "test_size": config.test_size,
            "random_seed": config.random_seed,
        },
    )

    # Implement your training logic here
    print("Training custom model...")
    print(f"Training data shape: {X_train.shape}")
    print(f"Test data shape: {X_test.shape}")

    # TODO: Add your model training code here

    # Log metrics
    # wandb.log({"metric_name": metric_value})
    wandb.finish()
{% else %}
    # Implement your training logic here
    print("Training custom model...")
    print(f"Training data shape: {X_train.shape}")
    print(f"Test data shape: {X_test.shape}")

    # TODO: Add your model training code here
{% endif %}
{% endif %}


def main():
    """Main training function."""
    # Load your data here
    # For demonstration, using synthetic data
    from sklearn.datasets import make_classification

    X, y = make_classification(
        n_samples=1000,
        n_features=20,
        n_informative=15,
        n_redundant=5,
        random_state=config.random_seed
    )

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=config.test_size, random_state=config.random_seed
    )

    print(f"Training samples: {len(X_train)}")
    print(f"Test samples: {len(X_test)}")

    # Train model
    train_model(X_train, y_train, X_test, y_test)


if __name__ == "__main__":
    main()
